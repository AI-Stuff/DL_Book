{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blackboard_ai.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHGwuxlpkfdKYK8QScOiBK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgntprg/DL_Book/blob/master/blackboard_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS7XyVaTFj-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mApl-ih2GIm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOgDJsdEFhvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-LchPYaFbYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GewHpyPFTLq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow_examples.models.pix2pix import pix2pix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ybwdX5Vn40z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image -= tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E74pmJT8jq4k",
        "colab_type": "text"
      },
      "source": [
        "We need to modify the training data such that we can make the result predictable by segmentation. There are only 2 classes which cna be predicted by segmentation, so it would be a binary problem.\n",
        "\n",
        "Shape of the mask would be (x, x, 1) with the final dimension used to represent the number of class outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D33AqT7qixgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (450, 600))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (450, 600))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "  \n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MofCKkfhAfiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFTkDrGH75N4",
        "colab_type": "text"
      },
      "source": [
        "Create a function which generates a target mask from an input image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ7k8SfL7uBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1 if white, 2 if black (this is shifted to 0 and 1 in normalize() )\n",
        "def make_mask(img):\n",
        "  mask = np.empty((img.shape[0], img.shape[1], 1))\n",
        "  for i, row in enumerate(img):\n",
        "    # row is a list of pixels for the image in the particular row\n",
        "    for j, col in enumerate(row):\n",
        "      if col[0] < 125:\n",
        "        mask[i][j][0] = 1\n",
        "      else: \n",
        "        mask[i][j][0] = 2\n",
        "  return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPfFCSAaiuOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "paths = []\n",
        " \n",
        "input_dir = 'gdrive/My Drive/ML/Projects/Blackboard_effect/images/input'\n",
        "output_dir = 'gdrive/My Drive/ML/Projects/Blackboard_effect/images/output'\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for file_name in os.listdir(input_dir):\n",
        "  \n",
        "  img = cv2.imread(os.path.join(input_dir, file_name))   # reads an image in the BGR format\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # BGR -> RGB\n",
        "  \n",
        "  img_filter = cv2.imread(os.path.join(output_dir, file_name)) \n",
        "  mask = make_mask(img_filter)\n",
        "\n",
        "  X.append([img])\n",
        "  y.append([mask])\n",
        "  display([img, mask])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5C9vbeWDgZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 1 # Black or white"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM7TTqZ4DmzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[224, 224, 3], include_top=False)\n",
        "\n",
        "# use activations of these layers\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 112x112\n",
        "    'block_3_expand_relu',   # 56x56\n",
        "    'block_6_expand_relu',   # 28x28\n",
        "    'block_13_expand_relu',  # 14x14\n",
        "    'block_16_project',      # 7x7\n",
        "]\n",
        "\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "down_stack.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3hTfsdGFOAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first param of upsample is pixels\n",
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3), # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3), # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3), # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3) # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj4sheJkHckj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unet_model(output_channels):\n",
        "  last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2, padding='same', activation='sigmoid') # sigmoid since only 2\n",
        "\n",
        "  inputs = tf.keras.layers.Input(shape=[224, 224, 3])\n",
        "  x = inputs\n",
        "\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1] # downsize all the way\n",
        "  skips = reversed(skips[:-1]) # reverse layer order, for residual (adds info from the encoder)\n",
        "\n",
        "  # upsampling and establish skip connection\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x) # apply upsampling \n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip]) # establish skip connections\n",
        "  \n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr_2YOuuIZ2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = unet_model(OUTPUT_CHANNELS)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkRxcluvInKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNfvCR3dItwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Mask shape:', mask.shape)\n",
        "for i in range(EPOCHS):\n",
        "  model_history = model.fit(X, y, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azcP1CBO5rSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGbekZGz2PhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_file = r'gdrive/My Drive/ML/Projects/Blackboard_effect/14.5.jpg'\n",
        "img = cv2.imread(input_file).astype(np.float32)  # reads an image in the BGR format\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # BGR -> RGB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yuB95TG4Mrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(np.array([img]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxDqL3YC5Uv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for mask in pred:\n",
        "  print(mask.shape)\n",
        "  color_img = mask * 255.0\n",
        "  color_img = cv2.cvtColor(color_img, cv2.COLOR_GRAY2RGB)\n",
        "  display([color_img])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCZMD3Kb98SV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  print(mask * 255)\n",
        "mask[0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsGRxU3VEab4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}